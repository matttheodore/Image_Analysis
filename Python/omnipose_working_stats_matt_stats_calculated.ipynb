{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnipose Segmentation from ImageJ Macro converted image directories\n",
    "\n",
    "This file is meant to aid in omnipose segmentation in a reproducible and streamlined way to help with automated image analysis especially early QC to adjust experimental and imaging parameters as needed to optimize S/N for the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for all chunks\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-23 14:56:15,811 [INFO] ** TORCH GPU version installed and working. **\n",
      ">>> GPU activated? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# omnipose setup and GPU\n",
    "from cellpose_omni import models, core\n",
    "import torch\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? {}'.format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "\n",
    "# Mapping dictionary for renaming channels\n",
    "channel_map = {'Phase': 'phase', 'eGFP': 'fish', 'DAPI': 'dapi'}\n",
    "\n",
    "# Root directory\n",
    "root_dir = r'C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2'  #this would be a directory where your biorep level folder is stored\n",
    "\n",
    "# Navigate through directories to find OME.TIFF files and rename them\n",
    "for biorep_dir in os.listdir(root_dir):\n",
    "    biorep_path = os.path.join(root_dir, biorep_dir)\n",
    "    if os.path.isdir(biorep_path):\n",
    "        for date_strain_dir in os.listdir(biorep_path):\n",
    "            date_strain_path = os.path.join(biorep_path, date_strain_dir)\n",
    "            if os.path.isdir(date_strain_path):\n",
    "                for sub_dir in os.listdir(date_strain_path):\n",
    "                    sub_dir_path = os.path.join(date_strain_path, sub_dir)\n",
    "                    if os.path.isdir(sub_dir_path):\n",
    "                        for img_data_dir in os.listdir(sub_dir_path):\n",
    "                            img_data_path = os.path.join(sub_dir_path, img_data_dir)\n",
    "                            if os.path.isdir(img_data_path):\n",
    "                                for file in os.listdir(img_data_path):\n",
    "                                    if file.endswith('.ome.tiff') or file.endswith('.ome.tif'):\n",
    "                                        file_path = os.path.join(img_data_path, file)\n",
    "                                        \n",
    "                                        # Read the OME.TIFF file to get channel names\n",
    "                                        reader = OmeTiffReader(file_path)\n",
    "                                        ome_metadata = reader.ome_metadata\n",
    "                                        channel_names = [channel.name for channel in ome_metadata.images[0].pixels.channels]\n",
    "                                        \n",
    "                                        # Rename folders and files based on channel names\n",
    "                                        for i, channel_name in enumerate(channel_names):\n",
    "                                            # Map the original channel name to the new name using the channel_map dictionary\n",
    "                                            mapped_name = channel_map.get(channel_name, channel_name)\n",
    "                                            \n",
    "                                            # Create the old and new folder names based on channel index\n",
    "                                            old_folder_name = f\"C{i+1}-MAX_sequence\"\n",
    "                                            new_folder_name = f\"{mapped_name}-MAX_sequence\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new folder names\n",
    "                                            old_folder_path = os.path.join(img_data_path, old_folder_name)\n",
    "                                            new_folder_path = os.path.join(img_data_path, new_folder_name)\n",
    "                                            \n",
    "                                            # If the old folder exists, rename it to the new folder name\n",
    "                                            if os.path.exists(old_folder_path):\n",
    "                                                shutil.move(old_folder_path, new_folder_path)\n",
    "                                            \n",
    "                                            # Rename individual single-page TIFF files inside the new folder\n",
    "                                            for single_tiff in os.listdir(new_folder_path):\n",
    "                                                # Check if the file starts with the old channel name\n",
    "                                                if single_tiff.startswith(f\"C{i+1}-MAX\"):\n",
    "                                                    # Create the full path to the old single-page TIFF file\n",
    "                                                    old_single_tiff_path = os.path.join(new_folder_path, single_tiff)\n",
    "                                                    \n",
    "                                                    # Create the new single-page TIFF file name based on mapped channel name\n",
    "                                                    new_single_tiff_name = single_tiff.replace(f\"C{i+1}-MAX\", f\"{mapped_name}-MAX\")\n",
    "                                                    \n",
    "                                                    # Create the full path to the new single-page TIFF file\n",
    "                                                    new_single_tiff_path = os.path.join(new_folder_path, new_single_tiff_name)\n",
    "                                                    \n",
    "                                                    # Rename the old single-page TIFF file to the new name\n",
    "                                                    shutil.move(old_single_tiff_path, new_single_tiff_path)\n",
    "                                            \n",
    "                                            # Create old and new multi-page TIFF file names based on channel index\n",
    "                                            old_file_name = f\"C{i+1}-MAX.tif\"\n",
    "                                            new_file_name = f\"{mapped_name}-MAX.tif\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new multi-page TIFF files\n",
    "                                            old_file_path = os.path.join(img_data_path, old_file_name)\n",
    "                                            new_file_path = os.path.join(img_data_path, new_file_name)\n",
    "                                            \n",
    "                                            # If the old multi-page TIFF file exists, rename it to the new name\n",
    "                                            if os.path.exists(old_file_path):\n",
    "                                                shutil.move(old_file_path, new_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Omnipose for Segmentation\n",
    "\n",
    "Here is the incorporation into the omnipose script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the images and QC to check images match expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting all the tiff files for omnipose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of images processed: 11\n",
      "No issues found in images.\n"
     ]
    }
   ],
   "source": [
    "from skimage import io  # Importing the io module from skimage for image reading\n",
    "\n",
    "# Initialize an empty list to store the full paths of all phase-MAX_sequence TIFF files.\n",
    "# This list will include both newly renamed and previously renamed phase files.\n",
    "all_phase_max_sequence_files = []\n",
    "\n",
    "# Counter for total images\n",
    "total_images = 0\n",
    "\n",
    "# Counter for images with issues\n",
    "issues_counter = 0\n",
    "\n",
    "# Use os.walk to navigate through the directory tree rooted at root_dir.\n",
    "# os.walk yields a 3-tuple (dirpath, dirnames, filenames) for each directory it visits.\n",
    "# dirpath is the path to the current directory, dirnames is a list of subdirectories in the current directory,\n",
    "# and filenames is a list of filenames in the current directory.\n",
    "\n",
    "# Loop through the directory structure\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dir in dirs:\n",
    "        if dir == \"phase-MAX_sequence\":\n",
    "            phase_folder_path = os.path.join(root, dir)\n",
    "            for file in os.listdir(phase_folder_path):\n",
    "                if file.endswith(\".tif\"):\n",
    "                    full_file_path = os.path.join(phase_folder_path, file)\n",
    "                    all_phase_max_sequence_files.append(full_file_path)\n",
    "                    \n",
    "                    # Read the image into an array\n",
    "                    img = io.imread(full_file_path)\n",
    "                    \n",
    "                    # Perform quality checks\n",
    "                    shape = img.shape\n",
    "                    dtype = img.dtype\n",
    "                    min_val, max_val = img.min(), img.max()\n",
    "\n",
    "                    # Increment the total_images counter\n",
    "                    total_images += 1\n",
    "\n",
    "                    #quality control checks here\n",
    "                    if shape != (512, 512) or min_val < 3500 or max_val > 35000:\n",
    "                        issues_counter += 1\n",
    "                        print(f\"Warning: Image at {full_file_path} has issues.\")\n",
    "                        print(f\"  - Original image shape: {shape}\")\n",
    "                        print(f\"  - Data type: {dtype}\")\n",
    "                        print(f\"  - Data range: min {min_val}, max {max_val}\")\n",
    "\n",
    "print(f\"\\nTotal number of images processed: {total_images}\")\n",
    "if issues_counter:\n",
    "    print(f\"Number of images with issues: {issues_counter}\")\n",
    "else:\n",
    "    print(\"No issues found in images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPU found. Switching to GPU mode.\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_uint \n",
    "import numpy as np\n",
    "from cellpose_omni import models, utils, io as cellpose_io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import time\n",
    "from tifffile import TiffFile, imwrite\n",
    "import re\n",
    "\n",
    "# Check for CUDA-enabled GPU availability\n",
    "# Uncomment this block when you want to switch to GPU computation\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability and set the gpu flag\n",
    "if torch.cuda.is_available():\n",
    "    gpu = True\n",
    "    print(\"CUDA-enabled GPU found. Switching to GPU mode.\")\n",
    "else:\n",
    "    gpu = False\n",
    "    print(\"No CUDA-enabled GPU found. Running on CPU.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-23 14:56:16,485 [INFO] >>bact_phase_omni<< model set to be used\n",
      "2023-10-23 14:56:16,495 [INFO] ** TORCH GPU version installed and working. **\n",
      "2023-10-23 14:56:16,495 [INFO] >>>> using GPU\n",
      "Elapsed time for the code chunk: 11.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define function to create subdirectories\n",
    "def create_sub_dirs(sequence_folder):\n",
    "    sub_dirs = ['masks', 'outlines']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(sequence_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Define Function for saving multi-page results\n",
    "def create_output_dirs(output_folder):\n",
    "    sub_dirs = ['cell_only', 'background_only']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(output_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Function to extract sequence numbers from filenames\n",
    "def extract_sequence_number(filename):\n",
    "    match = re.search(r'-(\\d{4})\\.tif', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function for Extracting the Multipage Tiff within Directory     \n",
    "def find_multipage_tiff(directory):\n",
    "    current_dir = directory\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    all_files = os.listdir(os.path.dirname(current_dir))\n",
    "    filtered_files = [f for f in all_files if \"LZ222\" in f and \"ome\" not in f]\n",
    "    return os.path.join(parent_dir, filtered_files[0])\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'bact_phase_omni'\n",
    "model = models.CellposeModel(gpu=gpu, model_type=model_name)\n",
    "\n",
    "# define parameters\n",
    "params = {\n",
    "    'channels': [0,0],  # Segment based on first channel, no second channel\n",
    "    'rescale': None,  # upscale or downscale your images, None = no rescaling\n",
    "    'mask_threshold': -1,  # erode or dilate masks with higher or lower values\n",
    "    'flow_threshold': 0,  # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "    'transparency': True,  # transparency in flow output\n",
    "    'omni': True,  # we can turn off Omnipose mask reconstruction, not advised\n",
    "    'cluster': True,  # use DBSCAN clustering\n",
    "    'resample': True,  # whether or not to run dynamics on rescaled grid or original grid\n",
    "    'verbose': False,  # turn on if you want to see more output\n",
    "    'tile': False,  # average the outputs from flipped (augmented) images; slower, usually not needed\n",
    "    'niter': None,  # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation\n",
    "    'augment': False,  # Can optionally rotate the image and average outputs, usually not needed\n",
    "    'affinity_seg': False,  # new feature, stay tuned...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## Segmentation and post-processing\n",
    "for file in sorted(all_phase_max_sequence_files):  # Note the sorting, should be grabbing a file based on its name and reading that image file\n",
    "    sequence_number = extract_sequence_number(os.path.basename(file))\n",
    "\n",
    "\n",
    "    # Read the image\n",
    "    image = imread(file)\n",
    "    \n",
    "    # Apply the model\n",
    "    masks, flows, styles = model.eval(image, **params)\n",
    "    \n",
    "    # Generate cell-only and background-only images\n",
    "    cell_only_image = image * (masks > 0)\n",
    "    background_only_image = image * (masks == 0)\n",
    "    \n",
    "    label_image = label(masks)\n",
    "\n",
    "    # Create subdirectories for saving within phase-max\n",
    "    directory = os.path.dirname(file)\n",
    "    create_sub_dirs(directory)\n",
    "    filename = os.path.basename(file)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "     # Find the corresponding multi-page TIFF\n",
    "    tiff_path = find_multipage_tiff(os.path.dirname(file)) # * i dont know why this is grabbed here seems out of place \n",
    "    with TiffFile(tiff_path) as tif: \n",
    "        multi_page_tiff = tif.asarray() #read image into a numpy array\n",
    "\n",
    "    # Initialize output folders\n",
    "    output_folder_cell_only = os.path.join(os.path.dirname(tiff_path), 'cell_only')\n",
    "    output_folder_bg_only = os.path.join(os.path.dirname(tiff_path), 'background_only')\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    create_output_dirs(output_folder_cell_only)\n",
    "    create_output_dirs(output_folder_bg_only)\n",
    "    \n",
    "    sequence_number = sequence_number -1\n",
    "\n",
    "# Apply the mask to each channel in each sequence (here an XY frame) and Z-plane, just use the current mask \n",
    "    if sequence_number < multi_page_tiff.shape[0]: \n",
    "    \n",
    "        for z in range(multi_page_tiff.shape[1]):\n",
    "            for channel in range(multi_page_tiff.shape[2]):\n",
    "                single_image = multi_page_tiff[sequence_number, z, channel, :, :]\n",
    "                single_image_cells = single_image * (masks > 0)\n",
    "                single_image_background = single_image * (masks == 0)\n",
    "                        \n",
    "                # Generate the output paths\n",
    "                output_cell_only_path = os.path.join(output_folder_cell_only, f\"frame_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                output_bg_only_path = os.path.join(output_folder_bg_only, f\"frame_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                        \n",
    "                # Save the cell-only and background-only images\n",
    "                imwrite(output_cell_only_path, single_image_cells)\n",
    "                imwrite(output_bg_only_path, single_image_background)\n",
    "    else:\n",
    "            print(f\"Skipping {sequence_number} as it is out of bounds.\")\n",
    "\n",
    "    # Modify the output paths\n",
    "    output_cell_only_path = os.path.join(directory, 'cell_only', f\"{base_name}_cell_only.tif\")\n",
    "    output_background_only_path = os.path.join(directory, 'background_only', f\"{base_name}_background_only.tif\")\n",
    "    output_outlines_path = os.path.join(directory, 'outlines', f\"{base_name}_outlines.txt\")\n",
    "    output_mask_path = os.path.join(directory, 'masks', f\"{base_name}_mask.tif\")\n",
    "    \n",
    "    # Save the images and outlines\n",
    "    cellpose_io.outlines_to_text(output_outlines_path, label_image)\n",
    "    imwrite(output_mask_path, masks.astype(np.uint16))\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time for the code chunk: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Now that I have all of the images post mask processing in an organized format I can look into reading them into the memory and performing statistics on them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>pixel_count</th>\n",
       "      <th>area_covered</th>\n",
       "      <th>frame</th>\n",
       "      <th>z_stack</th>\n",
       "      <th>channel</th>\n",
       "      <th>condition</th>\n",
       "      <th>time</th>\n",
       "      <th>strain</th>\n",
       "      <th>biorep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10242.878421</td>\n",
       "      <td>10060.0</td>\n",
       "      <td>19183</td>\n",
       "      <td>6387</td>\n",
       "      <td>870.647995</td>\n",
       "      <td>2.313901</td>\n",
       "      <td>8.834251</td>\n",
       "      <td>236793</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>uninf</td>\n",
       "      <td>LZ22225</td>\n",
       "      <td>10min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5763.509597</td>\n",
       "      <td>5732.0</td>\n",
       "      <td>15398</td>\n",
       "      <td>4049</td>\n",
       "      <td>470.939629</td>\n",
       "      <td>0.809239</td>\n",
       "      <td>4.273426</td>\n",
       "      <td>236793</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>uninf</td>\n",
       "      <td>LZ22225</td>\n",
       "      <td>10min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10212.855300</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>19272</td>\n",
       "      <td>6139</td>\n",
       "      <td>872.961733</td>\n",
       "      <td>2.334621</td>\n",
       "      <td>8.966507</td>\n",
       "      <td>236793</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uninf</td>\n",
       "      <td>LZ22225</td>\n",
       "      <td>10min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5452.585866</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>13049</td>\n",
       "      <td>3663</td>\n",
       "      <td>435.475669</td>\n",
       "      <td>0.556898</td>\n",
       "      <td>2.232659</td>\n",
       "      <td>236793</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>uninf</td>\n",
       "      <td>LZ22225</td>\n",
       "      <td>10min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10192.152762</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>18489</td>\n",
       "      <td>5804</td>\n",
       "      <td>858.448014</td>\n",
       "      <td>2.260109</td>\n",
       "      <td>8.405057</td>\n",
       "      <td>236793</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>uninf</td>\n",
       "      <td>LZ22225</td>\n",
       "      <td>10min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean   median    max   min     std_dev  skewness  kurtosis  \\\n",
       "0  10242.878421  10060.0  19183  6387  870.647995  2.313901  8.834251   \n",
       "1   5763.509597   5732.0  15398  4049  470.939629  0.809239  4.273426   \n",
       "2  10212.855300  10028.0  19272  6139  872.961733  2.334621  8.966507   \n",
       "3   5452.585866   5430.0  13049  3663  435.475669  0.556898  2.232659   \n",
       "4  10192.152762  10013.0  18489  5804  858.448014  2.260109  8.405057   \n",
       "\n",
       "   pixel_count  area_covered frame z_stack channel condition     time strain  \\\n",
       "0       236793      0.903294     0       0       0     uninf  LZ22225  10min   \n",
       "1       236793      0.903294     0       0       1     uninf  LZ22225  10min   \n",
       "2       236793      0.903294     0       1       0     uninf  LZ22225  10min   \n",
       "3       236793      0.903294     0       1       1     uninf  LZ22225  10min   \n",
       "4       236793      0.903294     0       2       0     uninf  LZ22225  10min   \n",
       "\n",
       "  biorep  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# Function to calculate image statistics\n",
    "def calculate_image_stats(image_path):\n",
    "    # Read the image\n",
    "    image = imread(image_path)\n",
    "    \n",
    "    # Filter out the zero pixels (artifacts from segmentation)\n",
    "    image = image[image > 0]\n",
    "    \n",
    "    # Initialize a dictionary to store the statistics\n",
    "    stats_dict = {}\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats_dict['mean'] = np.mean(image)\n",
    "    stats_dict['median'] = np.median(image)\n",
    "    stats_dict['max'] = np.max(image)\n",
    "    stats_dict['min'] = np.min(image)\n",
    "    stats_dict['std_dev'] = np.std(image)\n",
    "    stats_dict['skewness'] = scipy.stats.skew(image)\n",
    "    stats_dict['kurtosis'] = scipy.stats.kurtosis(image)\n",
    "    stats_dict['pixel_count'] = len(image)\n",
    "    stats_dict['area_covered'] = (len(image)/262144) # amount of area covered in the image by segmented pixels\n",
    "    \n",
    "    # Extract metadata from the file path\n",
    "    p = Path(image_path)\n",
    "\n",
    "    # From the deepest file level\n",
    "    try:\n",
    "        split_stem = p.stem.split('_')\n",
    "        frame = split_stem[1]\n",
    "        z_stack = split_stem[3]\n",
    "        channel = split_stem[5]\n",
    "        stats_dict['frame'] = frame\n",
    "        stats_dict['z_stack'] = z_stack\n",
    "        stats_dict['channel'] = channel\n",
    "    except IndexError:\n",
    "        print(f\"Failed to extract frame, z_stack, channel from {p.stem}\")\n",
    "\n",
    "    # From the directory structure\n",
    "    root_parts = root.split('\\\\')\n",
    "    try:\n",
    "        condition = root_parts[9].split('_')[-1].split('.')[0]  # 'inf' or 'uninf'\n",
    "        time = root_parts[9].split('_')[1]  # 10min, 20min, etc.\n",
    "        strain = root_parts[9].split('_')[2].split('.')[0]  # LZ222##\n",
    "        stats_dict['condition'] = condition\n",
    "        stats_dict['time'] = time\n",
    "        stats_dict['strain'] = strain\n",
    "    except IndexError:\n",
    "        print(f\"Failed to extract condition, time, strain from {root}\")\n",
    "\n",
    "\n",
    "    biorep = '1'  # All 1 in this case\n",
    "    stats_dict['biorep'] = biorep\n",
    "\n",
    "\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "# Initialize an empty DataFrame to store the image statistics and metadata\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Directory path (Replace this with the actual path)\n",
    "# root_dir = root_dir # this has been defined in the first chunk above, if need to redefine can do so here\n",
    "\n",
    "# Iterate through directories and sub-directories\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tif\") and ('cell_only' in root or 'background_only' in root):\n",
    "            file_path = os.path.join(root, file)  # Full path to the file\n",
    "            # Calculate image statistics\n",
    "            stats = calculate_image_stats(file_path)\n",
    "            \n",
    "            # Append the dictionary to the DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([stats])], ignore_index=True)\n",
    "\n",
    "\n",
    "# Show the DataFrame (For demonstration, will only display the head)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split stem: ['frame', '2', 'Z', '4', 'Channel', '2']\n"
     ]
    }
   ],
   "source": [
    "p = Path(file_path)\n",
    "\n",
    "print(\"Split stem:\", p.stem.split('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              mean   median    max   min      std_dev  skewness  kurtosis  \\\n",
      "0    10242.878421  10060.0  19183  6387   870.647995  2.313901  8.834251   \n",
      "1     5763.509597   5732.0  15398  4049   470.939629  0.809239  4.273426   \n",
      "2    10212.855300  10028.0  19272  6139   872.961733  2.334621  8.966507   \n",
      "3     5452.585866   5430.0  13049  3663   435.475669  0.556898  2.232659   \n",
      "4    10192.152762  10013.0  18489  5804   858.448014  2.260109  8.405057   \n",
      "..            ...      ...    ...   ...          ...       ...       ...   \n",
      "245   9648.284247   9625.0  14566  7184   726.518150  0.280868  0.408741   \n",
      "246  23426.886832  23524.5  47023  7520  6191.949586  0.110423 -0.159910   \n",
      "247   7816.201070   7592.5  15360  4499  1533.609511  0.677385  0.164033   \n",
      "248   9379.229577   9356.0  13599  7132   674.217729  0.253921  0.319319   \n",
      "249  22991.614535  23118.0  45961  7287  5976.425770  0.112240 -0.159848   \n",
      "\n",
      "     pixel_count  area_covered frame z_stack channel condition     time  \\\n",
      "0         236793      0.903294     0       0       0     uninf  LZ22225   \n",
      "1         236793      0.903294     0       0       1     uninf  LZ22225   \n",
      "2         236793      0.903294     0       1       0     uninf  LZ22225   \n",
      "3         236793      0.903294     0       1       1     uninf  LZ22225   \n",
      "4         236793      0.903294     0       2       0     uninf  LZ22225   \n",
      "..           ...           ...   ...     ...     ...       ...      ...   \n",
      "245        25608      0.097687     2       3       1       inf  LZ22225   \n",
      "246        25608      0.097687     2       3       2       inf  LZ22225   \n",
      "247        25608      0.097687     2       4       0       inf  LZ22225   \n",
      "248        25608      0.097687     2       4       1       inf  LZ22225   \n",
      "249        25608      0.097687     2       4       2       inf  LZ22225   \n",
      "\n",
      "    strain biorep  \n",
      "0    10min      1  \n",
      "1    10min      1  \n",
      "2    10min      1  \n",
      "3    10min      1  \n",
      "4    10min      1  \n",
      "..     ...    ...  \n",
      "245  20min      1  \n",
      "246  20min      1  \n",
      "247  20min      1  \n",
      "248  20min      1  \n",
      "249  20min      1  \n",
      "\n",
      "[250 rows x 16 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value_1</th>\n",
       "      <th>Value_2</th>\n",
       "      <th>Value_3</th>\n",
       "      <th>Value_4</th>\n",
       "      <th>Value_5</th>\n",
       "      <th>Value_6</th>\n",
       "      <th>Value_7</th>\n",
       "      <th>Value_8</th>\n",
       "      <th>Value_9</th>\n",
       "      <th>Value_10</th>\n",
       "      <th>Value_11</th>\n",
       "      <th>Value_12</th>\n",
       "      <th>Value_13</th>\n",
       "      <th>Value_14</th>\n",
       "      <th>Value_15</th>\n",
       "      <th>Value_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Value_1 Value_2 Value_3 Value_4 Value_5 Value_6 Value_7 Value_8 Value_9  \\\n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "  Value_10 Value_11 Value_12 Value_13 Value_14 Value_15 Value_16  \n",
       "0      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame with 10 rows and 16 columns\n",
    "num_objects = 10\n",
    "columns = [f'Value_{i+1}' for i in range(16)]\n",
    "df = pd.DataFrame(index=range(num_objects), columns=columns)\n",
    "\n",
    "# Define a function to simulate the dict of 16 values for each object\n",
    "def compute_values_dict(obj):\n",
    "    return {f'Value_{i+1}': obj * (i+1) for i in range(16)}\n",
    "\n",
    "# Populate the DataFrame row by row\n",
    "for i in range(num_objects):\n",
    "    computed_values = calculate_image_stats(file_path)\n",
    "    df = df.append() computed_values\n",
    "\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnipose_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
