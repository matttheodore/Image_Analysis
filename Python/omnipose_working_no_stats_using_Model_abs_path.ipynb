{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnipose Segmentation from ImageJ Macro converted image directories\n",
    "\n",
    "This file is meant to aid in omnipose segmentation in a reproducible and streamlined way to help with automated image analysis especially early QC to adjust experimental and imaging parameters as needed to optimize S/N for the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aicsimageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mattt\\Fiji.app\\Image_Analysis\\Python\\omnipose_working_no_stats_using_Model_abs_path.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maicsimageio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreaders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mome_tiff_reader\u001b[39;00m \u001b[39mimport\u001b[39;00m OmeTiffReader\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'aicsimageio'"
     ]
    }
   ],
   "source": [
    "# Imports for all chunks\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omnipose setup and GPU\n",
    "from cellpose_omni import models, core\n",
    "import torch\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? {}'.format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "\n",
    "# Mapping dictionary for renaming channels\n",
    "channel_map = {'Phase': 'phase', 'eGFP': 'fish', 'DAPI': 'dapi'}\n",
    "\n",
    "# Root directory\n",
    "root_dir = r'C:\\Users\\mattt\\Documents\\Omni\\Model_evaluations\\new_model'  #this would be a directory where your biorep level folder is stored\n",
    "\n",
    "# Navigate through directories to find OME.TIFF files and rename them\n",
    "for biorep_dir in os.listdir(root_dir):\n",
    "    biorep_path = os.path.join(root_dir, biorep_dir)\n",
    "    if os.path.isdir(biorep_path):\n",
    "        for date_strain_dir in os.listdir(biorep_path):\n",
    "            date_strain_path = os.path.join(biorep_path, date_strain_dir)\n",
    "            if os.path.isdir(date_strain_path):\n",
    "                for sub_dir in os.listdir(date_strain_path):\n",
    "                    sub_dir_path = os.path.join(date_strain_path, sub_dir)\n",
    "                    if os.path.isdir(sub_dir_path):\n",
    "                        for img_data_dir in os.listdir(sub_dir_path):\n",
    "                            img_data_path = os.path.join(sub_dir_path, img_data_dir)\n",
    "                            if os.path.isdir(img_data_path):\n",
    "                                for file in os.listdir(img_data_path):\n",
    "                                    if file.endswith('.ome.tiff') or file.endswith('.ome.tif'):\n",
    "                                        file_path = os.path.join(img_data_path, file)\n",
    "                                        \n",
    "                                        # Read the OME.TIFF file to get channel names\n",
    "                                        reader = OmeTiffReader(file_path)\n",
    "                                        ome_metadata = reader.ome_metadata\n",
    "                                        channel_names = [channel.name for channel in ome_metadata.images[0].pixels.channels]\n",
    "                                        \n",
    "                                        # Rename folders and files based on channel names\n",
    "                                        for i, channel_name in enumerate(channel_names):\n",
    "                                            # Map the original channel name to the new name using the channel_map dictionary\n",
    "                                            mapped_name = channel_map.get(channel_name, channel_name)\n",
    "                                            \n",
    "                                            # Create the old and new folder names based on channel index\n",
    "                                            old_folder_name = f\"C{i+1}-MAX_sequence\"\n",
    "                                            new_folder_name = f\"{mapped_name}-MAX_sequence\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new folder names\n",
    "                                            old_folder_path = os.path.join(img_data_path, old_folder_name)\n",
    "                                            new_folder_path = os.path.join(img_data_path, new_folder_name)\n",
    "                                            \n",
    "                                            # If the old folder exists, rename it to the new folder name\n",
    "                                            if os.path.exists(old_folder_path):\n",
    "                                                shutil.move(old_folder_path, new_folder_path)\n",
    "                                            \n",
    "                                            # Rename individual single-page TIFF files inside the new folder\n",
    "                                            for single_tiff in os.listdir(new_folder_path):\n",
    "                                                # Check if the file starts with the old channel name\n",
    "                                                if single_tiff.startswith(f\"C{i+1}-MAX\"):\n",
    "                                                    # Create the full path to the old single-page TIFF file\n",
    "                                                    old_single_tiff_path = os.path.join(new_folder_path, single_tiff)\n",
    "                                                    \n",
    "                                                    # Create the new single-page TIFF file name based on mapped channel name\n",
    "                                                    new_single_tiff_name = single_tiff.replace(f\"C{i+1}-MAX\", f\"{mapped_name}-MAX\")\n",
    "                                                    \n",
    "                                                    # Create the full path to the new single-page TIFF file\n",
    "                                                    new_single_tiff_path = os.path.join(new_folder_path, new_single_tiff_name)\n",
    "                                                    \n",
    "                                                    # Rename the old single-page TIFF file to the new name\n",
    "                                                    shutil.move(old_single_tiff_path, new_single_tiff_path)\n",
    "                                            \n",
    "                                            # Create old and new multi-page TIFF file names based on channel index\n",
    "                                            old_file_name = f\"C{i+1}-MAX.tif\"\n",
    "                                            new_file_name = f\"{mapped_name}-MAX.tif\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new multi-page TIFF files\n",
    "                                            old_file_path = os.path.join(img_data_path, old_file_name)\n",
    "                                            new_file_path = os.path.join(img_data_path, new_file_name)\n",
    "                                            \n",
    "                                            # If the old multi-page TIFF file exists, rename it to the new name\n",
    "                                            if os.path.exists(old_file_path):\n",
    "                                                shutil.move(old_file_path, new_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Omnipose for Segmentation\n",
    "\n",
    "Here is the incorporation into the omnipose script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the images and QC to check images match expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting all the tiff files for omnipose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of images processed: 56\n",
      "No issues found in images.\n"
     ]
    }
   ],
   "source": [
    "from skimage import io  # Importing the io module from skimage for image reading\n",
    "\n",
    "# Initialize an empty list to store the full paths of all phase-MAX_sequence TIFF files.\n",
    "# This list will include both newly renamed and previously renamed phase files.\n",
    "all_phase_max_sequence_files = []\n",
    "\n",
    "# Counter for total images\n",
    "total_images = 0\n",
    "\n",
    "# Counter for images with issues\n",
    "issues_counter = 0\n",
    "\n",
    "# Use os.walk to navigate through the directory tree rooted at root_dir.\n",
    "# os.walk yields a 3-tuple (dirpath, dirnames, filenames) for each directory it visits.\n",
    "# dirpath is the path to the current directory, dirnames is a list of subdirectories in the current directory,\n",
    "# and filenames is a list of filenames in the current directory.\n",
    "\n",
    "# Loop through the directory structure\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dir in dirs:\n",
    "        if dir == \"phase-MAX_sequence\":\n",
    "            phase_folder_path = os.path.join(root, dir)\n",
    "            for file in os.listdir(phase_folder_path):\n",
    "                if file.endswith(\".tif\"):\n",
    "                    full_file_path = os.path.join(phase_folder_path, file)\n",
    "                    all_phase_max_sequence_files.append(full_file_path)\n",
    "                    \n",
    "                    # Read the image into an array\n",
    "                    img = io.imread(full_file_path)\n",
    "                    \n",
    "                    # Perform quality checks\n",
    "                    shape = img.shape\n",
    "                    dtype = img.dtype\n",
    "                    min_val, max_val = img.min(), img.max()\n",
    "\n",
    "                    # Increment the total_images counter\n",
    "                    total_images += 1\n",
    "\n",
    "                    #quality control checks here\n",
    "                    if shape != (512, 512) or min_val < 3500 or max_val > 35000:\n",
    "                        issues_counter += 1\n",
    "                        print(f\"Warning: Image at {full_file_path} has issues.\")\n",
    "                        print(f\"  - Original image shape: {shape}\")\n",
    "                        print(f\"  - Data type: {dtype}\")\n",
    "                        print(f\"  - Data range: min {min_val}, max {max_val}\")\n",
    "\n",
    "print(f\"\\nTotal number of images processed: {total_images}\")\n",
    "if issues_counter:\n",
    "    print(f\"Number of images with issues: {issues_counter}\")\n",
    "else:\n",
    "    print(\"No issues found in images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cellpose_omni'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mattt\\Fiji.app\\Image_Analysis\\Python\\omnipose_working_no_stats_using_Model_abs_path.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m \u001b[39mimport\u001b[39;00m img_as_uint \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcellpose_omni\u001b[39;00m \u001b[39mimport\u001b[39;00m models, utils, io \u001b[39mas\u001b[39;00m cellpose_io\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmeasure\u001b[39;00m \u001b[39mimport\u001b[39;00m label, regionprops\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolor\u001b[39;00m \u001b[39mimport\u001b[39;00m label2rgb\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cellpose_omni'"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_uint \n",
    "import numpy as np\n",
    "from cellpose_omni import models, utils, io as cellpose_io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import time\n",
    "from tifffile import TiffFile, imwrite\n",
    "from tifffile import TiffFile, imsave\n",
    "import re\n",
    "\n",
    "# Check for CUDA-enabled GPU availability\n",
    "# Uncomment this block when you want to switch to GPU computation\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability and set the gpu flag\n",
    "if torch.cuda.is_available():\n",
    "    gpu = True\n",
    "    print(\"CUDA-enabled GPU found. Switching to GPU mode.\")\n",
    "else:\n",
    "    gpu = False\n",
    "    print(\"No CUDA-enabled GPU found. Running on CPU.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-12 11:18:19,098 [INFO] ** TORCH GPU version installed and working. **\n",
      "2023-12-12 11:18:19,101 [INFO] >>>> using GPU\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CPnet:\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.running_mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.running_var: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.2.weight: copying a param with shape torch.Size([32, 2, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.running_mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.running_var: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.1.weight: copying a param with shape torch.Size([32, 2, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 1, 1, 1]).\n\tsize mismatch for output.2.weight: copying a param with shape torch.Size([4, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([5, 32, 1, 1]).\n\tsize mismatch for output.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mattt\\Fiji.app\\Image_Analysis\\Python\\omnipose_working_no_stats_using_Model_abs_path.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Initialize model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmattt\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOmni\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfinal_4000_epoch_cellpose_residual_on_style_on_concatenation_off_omni_nclasses_4_omni_retrain_2023_11_01_01_34_28.551587\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model \u001b[39m=\u001b[39m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mCellposeModel(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     pretrained_model\u001b[39m=\u001b[39;49mmodel_path, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     gpu\u001b[39m=\u001b[39;49mgpu, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     omni\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     nclasses\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,  \u001b[39m# same as training\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     nchan\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m      \u001b[39m# same as training\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# define parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mchannels\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],  \u001b[39m# Segment based on first channel, no second channel\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrescale\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,  \u001b[39m# upscale or downscale your images, None = no rescaling\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnChan\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m4\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mattt/Fiji.app/Image_Analysis/Python/omnipose_working_no_stats_using_Model_abs_path.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\mattt\\anaconda3\\envs\\omnipose_gpu\\lib\\site-packages\\cellpose_omni\\models.py:496\u001b[0m, in \u001b[0;36mCellposeModel.__init__\u001b[1;34m(self, gpu, pretrained_model, model_type, net_avg, use_torch, diam_mean, device, residual_on, style_on, concatenation, nchan, nclasses, dim, omni, checkpoint, dropout, kernel_size)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model \u001b[39m=\u001b[39m pretrained_model\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model)\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    487\u001b[0m     \n\u001b[0;32m    488\u001b[0m     \u001b[39m# dataparallel A1\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[39m# if self.torch and gpu:\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     \u001b[39m#     self.net = nn.DataParallel(self.net)\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet\u001b[39m.\u001b[39;49mload_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpretrained_model[\u001b[39m0\u001b[39;49m], cpu\u001b[39m=\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpu))\n\u001b[0;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtorch:\n\u001b[0;32m    500\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mcollect_params()\u001b[39m.\u001b[39mgrad_req \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnull\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mattt\\anaconda3\\envs\\omnipose_gpu\\lib\\site-packages\\cellpose_omni\\resnet_torch.py:295\u001b[0m, in \u001b[0;36mCPnet.load_model\u001b[1;34m(self, filename, cpu)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, filename, cpu\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cpu:\n\u001b[1;32m--> 295\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(filename,map_location\u001b[39m=\u001b[39;49mtorch_GPU))\n\u001b[0;32m    296\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbase,\n\u001b[0;32m    298\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnout,\n\u001b[0;32m    299\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msz,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_dropout,\n\u001b[0;32m    307\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size)\n",
      "File \u001b[1;32mc:\\Users\\mattt\\anaconda3\\envs\\omnipose_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CPnet:\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.running_mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.0.running_var: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.conv.conv_0.2.weight: copying a param with shape torch.Size([32, 2, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 3]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.running_mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.0.running_var: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for downsample.down.res_down_0.proj.1.weight: copying a param with shape torch.Size([32, 2, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 1, 1, 1]).\n\tsize mismatch for output.2.weight: copying a param with shape torch.Size([4, 32, 1, 1]) from checkpoint, the shape in current model is torch.Size([5, 32, 1, 1]).\n\tsize mismatch for output.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([5])."
     ]
    }
   ],
   "source": [
    "# Define function to create subdirectories\n",
    "def create_sub_dirs(sequence_folder):\n",
    "    sub_dirs = ['masks', 'outlines']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(sequence_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Define Function for saving multi-page results\n",
    "def create_output_dirs(output_folder):\n",
    "    sub_dirs = ['cell_only', 'background_only']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(output_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Function to extract sequence numbers from filenames\n",
    "def extract_sequence_number(filename):\n",
    "    match = re.search(r'-(\\d{4})\\.tif', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function for Extracting the Multipage Tiff within Directory     \n",
    "def find_multipage_tiff(directory):\n",
    "    current_dir = directory\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    all_files = os.listdir(os.path.dirname(current_dir))\n",
    "    filtered_files = [f for f in all_files if \"LZ222\" in f and \"ome\" not in f]\n",
    "    return os.path.join(parent_dir, filtered_files[0])\n",
    "\n",
    "# Initialize model\n",
    "model_path = r\"C:\\Users\\mattt\\Documents\\Omni\\final_4000_epoch_cellpose_residual_on_style_on_concatenation_off_omni_nclasses_4_omni_retrain_2023_11_01_01_34_28.551587\"\n",
    "model = model = models.CellposeModel(\n",
    "    pretrained_model=model_path, \n",
    "    gpu=gpu, \n",
    "    omni=True, \n",
    "    nclasses=4,  # same as training\n",
    "    nchan=1      # same as training\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# define parameters\n",
    "params = {\n",
    "    'channels': [0,0],  # Segment based on first channel, no second channel\n",
    "    'rescale': None,  # upscale or downscale your images, None = no rescaling\n",
    "    'mask_threshold': -1,  # erode or dilate masks with higher or lower values\n",
    "    'flow_threshold': 0,  # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "    'transparency': True,  # transparency in flow output\n",
    "    'omni': True,  # we can turn off Omnipose mask reconstruction, not advised\n",
    "    'cluster': True,  # use DBSCAN clustering\n",
    "    'resample': True,  # whether or not to run dynamics on rescaled grid or original grid\n",
    "    'verbose': False,  # turn on if you want to see more output\n",
    "    'tile': False,  # average the outputs from flipped (augmented) images; slower, usually not needed\n",
    "    'niter': None,  # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation\n",
    "    'augment': False,  # Can optionally rotate the image and average outputs, usually not needed\n",
    "    'affinity_seg': False,  # new feature, stay tuned...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## Segmentation and post-processing\n",
    "for file in sorted(all_phase_max_sequence_files):  # Note the sorting, should be grabbing a file based on its name and reading that image file\n",
    "    sequence_number = extract_sequence_number(os.path.basename(file))\n",
    "\n",
    "\n",
    "    # Read the image\n",
    "    image = imread(file)\n",
    "    \n",
    "    # Apply the model\n",
    "    masks, flows, styles = model.eval(image, **params)\n",
    "    \n",
    "    # Generate cell-only and background-only images\n",
    "    cell_only_image = image * (masks > 0)\n",
    "    background_only_image = image * (masks == 0)\n",
    "    \n",
    "    label_image = label(masks)\n",
    "\n",
    "    # Create subdirectories for saving within phase-max\n",
    "    directory = os.path.dirname(file)\n",
    "    create_sub_dirs(directory)\n",
    "    filename = os.path.basename(file)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "     # Find the corresponding multi-page TIFF\n",
    "    tiff_path = find_multipage_tiff(os.path.dirname(file)) # * i dont know why this is grabbed here seems out of place \n",
    "    with TiffFile(tiff_path) as tif: \n",
    "        multi_page_tiff = tif.asarray() #read image into a numpy array\n",
    "\n",
    "    # Initialize output folders\n",
    "    output_folder_cell_only = os.path.join(os.path.dirname(tiff_path), 'cell_only')\n",
    "    output_folder_bg_only = os.path.join(os.path.dirname(tiff_path), 'background_only')\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    create_output_dirs(output_folder_cell_only)\n",
    "    create_output_dirs(output_folder_bg_only)\n",
    "    \n",
    "    sequence_number = sequence_number -1\n",
    "\n",
    "# Apply the mask to each channel in each timepoint and Z-plane, just use the current mask \n",
    "    if sequence_number < multi_page_tiff.shape[0]: \n",
    "    \n",
    "        for z in range(multi_page_tiff.shape[1]):\n",
    "            for channel in range(multi_page_tiff.shape[2]):\n",
    "                single_image = multi_page_tiff[sequence_number, z, channel, :, :]\n",
    "                single_image_cells = single_image * (masks > 0)\n",
    "                single_image_background = single_image * (masks == 0)\n",
    "                        \n",
    "                # Generate the output paths\n",
    "                output_cell_only_path = os.path.join(output_folder_cell_only, f\"Time_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                output_bg_only_path = os.path.join(output_folder_bg_only, f\"Time_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                        \n",
    "                # Save the cell-only and background-only images\n",
    "                imsave(output_cell_only_path, single_image_cells)\n",
    "                imsave(output_bg_only_path, single_image_background)\n",
    "    else:\n",
    "            print(f\"Skipping timepoint {adjusted_timepoint} as it is out of bounds.\")\n",
    "\n",
    "    # Modify the output paths\n",
    "    output_cell_only_path = os.path.join(directory, 'cell_only', f\"{base_name}_cell_only.tif\")\n",
    "    output_background_only_path = os.path.join(directory, 'background_only', f\"{base_name}_background_only.tif\")\n",
    "    output_outlines_path = os.path.join(directory, 'outlines', f\"{base_name}_outlines.txt\")\n",
    "    output_mask_path = os.path.join(directory, 'masks', f\"{base_name}_mask.tif\")\n",
    "    \n",
    "    # Save the images and outlines\n",
    "    outlines = utils.outlines_list(masks)\n",
    "    cellpose_io.outlines_to_text(output_outlines_path, outlines)\n",
    "    imsave(output_mask_path, masks.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#print(directory)\n",
    "#print(file)\n",
    "#find_multipage_tiff(directory)\n",
    "# Print sorted file names to verify the order\n",
    "#list(sorted(all_phase_max_sequence_files))\n",
    "#single_image = multi_page_tiff[timepoint, z, channel, :, :]\n",
    "#single_image.shape\n",
    "#print(\"Shape of multi_page_tiff:\", multi_page_tiff.shape)\n",
    "#print(\"Current Timepoint:\", timepoint)\n",
    "#print(sequence_number)\n",
    "extract_sequence_number(os.path.basename(file))\n",
    "print((multi_page_tiff.shape[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnipose_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
