{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnipose Segmentation from ImageJ Macro converted image directories\n",
    "\n",
    "This file is meant to aid in omnipose segmentation in a reproducible and streamlined way to help with automated image analysis especially early QC to adjust experimental and imaging parameters as needed to optimize S/N for the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for all chunks\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-24 12:23:37,617 [INFO] ** TORCH GPU version installed and working. **\n",
      ">>> GPU activated? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# omnipose setup and GPU\n",
    "from cellpose_omni import models, core\n",
    "import torch\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? {}'.format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "\n",
    "# Mapping dictionary for renaming channels\n",
    "channel_map = {'Phase': 'phase', 'eGFP': 'fish', 'DAPI': 'dapi'}\n",
    "\n",
    "# Root directory\n",
    "root_dir = r'C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2'  #this would be a directory where your biorep level folder is stored\n",
    "\n",
    "# Navigate through directories to find OME.TIFF files and rename them\n",
    "for biorep_dir in os.listdir(root_dir):\n",
    "    biorep_path = os.path.join(root_dir, biorep_dir)\n",
    "    if os.path.isdir(biorep_path):\n",
    "        for date_strain_dir in os.listdir(biorep_path):\n",
    "            date_strain_path = os.path.join(biorep_path, date_strain_dir)\n",
    "            if os.path.isdir(date_strain_path):\n",
    "                for sub_dir in os.listdir(date_strain_path):\n",
    "                    sub_dir_path = os.path.join(date_strain_path, sub_dir)\n",
    "                    if os.path.isdir(sub_dir_path):\n",
    "                        for img_data_dir in os.listdir(sub_dir_path):\n",
    "                            img_data_path = os.path.join(sub_dir_path, img_data_dir)\n",
    "                            if os.path.isdir(img_data_path):\n",
    "                                for file in os.listdir(img_data_path):\n",
    "                                    if file.endswith('.ome.tiff') or file.endswith('.ome.tif'):\n",
    "                                        file_path = os.path.join(img_data_path, file)\n",
    "                                        \n",
    "                                        # Read the OME.TIFF file to get channel names\n",
    "                                        reader = OmeTiffReader(file_path)\n",
    "                                        ome_metadata = reader.ome_metadata\n",
    "                                        channel_names = [channel.name for channel in ome_metadata.images[0].pixels.channels]\n",
    "                                        \n",
    "                                        # Rename folders and files based on channel names\n",
    "                                        for i, channel_name in enumerate(channel_names):\n",
    "                                            # Map the original channel name to the new name using the channel_map dictionary\n",
    "                                            mapped_name = channel_map.get(channel_name, channel_name)\n",
    "                                            \n",
    "                                            # Create the old and new folder names based on channel index\n",
    "                                            old_folder_name = f\"C{i+1}-MAX_sequence\"\n",
    "                                            new_folder_name = f\"{mapped_name}-MAX_sequence\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new folder names\n",
    "                                            old_folder_path = os.path.join(img_data_path, old_folder_name)\n",
    "                                            new_folder_path = os.path.join(img_data_path, new_folder_name)\n",
    "                                            \n",
    "                                            # If the old folder exists, rename it to the new folder name\n",
    "                                            if os.path.exists(old_folder_path):\n",
    "                                                shutil.move(old_folder_path, new_folder_path)\n",
    "                                            \n",
    "                                            # Rename individual single-page TIFF files inside the new folder\n",
    "                                            for single_tiff in os.listdir(new_folder_path):\n",
    "                                                # Check if the file starts with the old channel name\n",
    "                                                if single_tiff.startswith(f\"C{i+1}-MAX\"):\n",
    "                                                    # Create the full path to the old single-page TIFF file\n",
    "                                                    old_single_tiff_path = os.path.join(new_folder_path, single_tiff)\n",
    "                                                    \n",
    "                                                    # Create the new single-page TIFF file name based on mapped channel name\n",
    "                                                    new_single_tiff_name = single_tiff.replace(f\"C{i+1}-MAX\", f\"{mapped_name}-MAX\")\n",
    "                                                    \n",
    "                                                    # Create the full path to the new single-page TIFF file\n",
    "                                                    new_single_tiff_path = os.path.join(new_folder_path, new_single_tiff_name)\n",
    "                                                    \n",
    "                                                    # Rename the old single-page TIFF file to the new name\n",
    "                                                    shutil.move(old_single_tiff_path, new_single_tiff_path)\n",
    "                                            \n",
    "                                            # Create old and new multi-page TIFF file names based on channel index\n",
    "                                            old_file_name = f\"C{i+1}-MAX.tif\"\n",
    "                                            new_file_name = f\"{mapped_name}-MAX.tif\"\n",
    "                                            \n",
    "                                            # Create the full path to the old and new multi-page TIFF files\n",
    "                                            old_file_path = os.path.join(img_data_path, old_file_name)\n",
    "                                            new_file_path = os.path.join(img_data_path, new_file_name)\n",
    "                                            \n",
    "                                            # If the old multi-page TIFF file exists, rename it to the new name\n",
    "                                            if os.path.exists(old_file_path):\n",
    "                                                shutil.move(old_file_path, new_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Omnipose for Segmentation\n",
    "\n",
    "Here is the incorporation into the omnipose script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the images and QC to check images match expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting all the tiff files for omnipose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of images processed: 11\n",
      "No issues found in images.\n"
     ]
    }
   ],
   "source": [
    "from skimage import io  # Importing the io module from skimage for image reading\n",
    "\n",
    "# Initialize an empty list to store the full paths of all phase-MAX_sequence TIFF files.\n",
    "# This list will include both newly renamed and previously renamed phase files.\n",
    "all_phase_max_sequence_files = []\n",
    "\n",
    "# Counter for total images\n",
    "total_images = 0\n",
    "\n",
    "# Counter for images with issues\n",
    "issues_counter = 0\n",
    "\n",
    "# Use os.walk to navigate through the directory tree rooted at root_dir.\n",
    "# os.walk yields a 3-tuple (dirpath, dirnames, filenames) for each directory it visits.\n",
    "# dirpath is the path to the current directory, dirnames is a list of subdirectories in the current directory,\n",
    "# and filenames is a list of filenames in the current directory.\n",
    "\n",
    "# Loop through the directory structure\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dir in dirs:\n",
    "        if dir == \"phase-MAX_sequence\":\n",
    "            phase_folder_path = os.path.join(root, dir)\n",
    "            for file in os.listdir(phase_folder_path):\n",
    "                if file.endswith(\".tif\"):\n",
    "                    full_file_path = os.path.join(phase_folder_path, file)\n",
    "                    all_phase_max_sequence_files.append(full_file_path)\n",
    "                    \n",
    "                    # Read the image into an array\n",
    "                    img = io.imread(full_file_path)\n",
    "                    \n",
    "                    # Perform quality checks\n",
    "                    shape = img.shape\n",
    "                    dtype = img.dtype\n",
    "                    min_val, max_val = img.min(), img.max()\n",
    "\n",
    "                    # Increment the total_images counter\n",
    "                    total_images += 1\n",
    "\n",
    "                    #quality control checks here\n",
    "                    if shape != (512, 512) or min_val < 3500 or max_val > 35000:\n",
    "                        issues_counter += 1\n",
    "                        print(f\"Warning: Image at {full_file_path} has issues.\")\n",
    "                        print(f\"  - Original image shape: {shape}\")\n",
    "                        print(f\"  - Data type: {dtype}\")\n",
    "                        print(f\"  - Data range: min {min_val}, max {max_val}\")\n",
    "\n",
    "print(f\"\\nTotal number of images processed: {total_images}\")\n",
    "if issues_counter:\n",
    "    print(f\"Number of images with issues: {issues_counter}\")\n",
    "else:\n",
    "    print(\"No issues found in images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPU found. Switching to GPU mode.\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_uint \n",
    "import numpy as np\n",
    "from cellpose_omni import models, utils, io as cellpose_io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import time\n",
    "from tifffile import TiffFile, imwrite\n",
    "import re\n",
    "\n",
    "# Check for CUDA-enabled GPU availability\n",
    "# Uncomment this block when you want to switch to GPU computation\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability and set the gpu flag\n",
    "if torch.cuda.is_available():\n",
    "    gpu = True\n",
    "    print(\"CUDA-enabled GPU found. Switching to GPU mode.\")\n",
    "else:\n",
    "    gpu = False\n",
    "    print(\"No CUDA-enabled GPU found. Running on CPU.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-24 12:23:38,271 [INFO] >>bact_phase_omni<< model set to be used\n",
      "2023-10-24 12:23:38,273 [INFO] ** TORCH GPU version installed and working. **\n",
      "2023-10-24 12:23:38,274 [INFO] >>>> using GPU\n",
      "Elapsed time for the code chunk: 9.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define function to create subdirectories\n",
    "def create_sub_dirs(sequence_folder):\n",
    "    sub_dirs = ['masks', 'outlines']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(sequence_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Define Function for saving multi-page results\n",
    "def create_output_dirs(output_folder):\n",
    "    sub_dirs = ['cell_only', 'background_only']\n",
    "    for sub_dir in sub_dirs:\n",
    "        sub_dir_path = os.path.join(output_folder, sub_dir)\n",
    "        if not os.path.exists(sub_dir_path):\n",
    "            os.makedirs(sub_dir_path)\n",
    "\n",
    "# Function to extract sequence numbers from filenames\n",
    "def extract_sequence_number(filename):\n",
    "    match = re.search(r'-(\\d{4})\\.tif', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function for Extracting the Multipage Tiff within Directory     \n",
    "def find_multipage_tiff(directory):\n",
    "    current_dir = directory\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    all_files = os.listdir(os.path.dirname(current_dir))\n",
    "    filtered_files = [f for f in all_files if \"LZ222\" in f and \"ome\" not in f]\n",
    "    return os.path.join(parent_dir, filtered_files[0])\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'bact_phase_omni'\n",
    "model = models.CellposeModel(gpu=gpu, model_type=model_name)\n",
    "\n",
    "# define parameters\n",
    "params = {\n",
    "    'channels': [0,0],  # Segment based on first channel, no second channel\n",
    "    'rescale': None,  # upscale or downscale your images, None = no rescaling\n",
    "    'mask_threshold': -1,  # erode or dilate masks with higher or lower values\n",
    "    'flow_threshold': 0,  # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "    'transparency': True,  # transparency in flow output\n",
    "    'omni': True,  # we can turn off Omnipose mask reconstruction, not advised\n",
    "    'cluster': True,  # use DBSCAN clustering\n",
    "    'resample': True,  # whether or not to run dynamics on rescaled grid or original grid\n",
    "    'verbose': False,  # turn on if you want to see more output\n",
    "    'tile': False,  # average the outputs from flipped (augmented) images; slower, usually not needed\n",
    "    'niter': None,  # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation\n",
    "    'augment': False,  # Can optionally rotate the image and average outputs, usually not needed\n",
    "    'affinity_seg': False,  # new feature, stay tuned...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## Segmentation and post-processing\n",
    "for file in sorted(all_phase_max_sequence_files):  # Note the sorting, should be grabbing a file based on its name and reading that image file\n",
    "    sequence_number = extract_sequence_number(os.path.basename(file))\n",
    "\n",
    "\n",
    "    # Read the image\n",
    "    image = imread(file)\n",
    "    \n",
    "    # Apply the model\n",
    "    masks, flows, styles = model.eval(image, **params)\n",
    "    \n",
    "    # Generate cell-only and background-only images\n",
    "    cell_only_image = image * (masks > 0)\n",
    "    background_only_image = image * (masks == 0)\n",
    "    \n",
    "    label_image = label(masks)\n",
    "\n",
    "    # Create subdirectories for saving within phase-max\n",
    "    directory = os.path.dirname(file)\n",
    "    create_sub_dirs(directory)\n",
    "    filename = os.path.basename(file)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "     # Find the corresponding multi-page TIFF\n",
    "    tiff_path = find_multipage_tiff(os.path.dirname(file)) # * i dont know why this is grabbed here seems out of place \n",
    "    with TiffFile(tiff_path) as tif: \n",
    "        multi_page_tiff = tif.asarray() #read image into a numpy array\n",
    "\n",
    "    # Initialize output folders\n",
    "    output_folder_cell_only = os.path.join(os.path.dirname(tiff_path), 'cell_only')\n",
    "    output_folder_bg_only = os.path.join(os.path.dirname(tiff_path), 'background_only')\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    create_output_dirs(output_folder_cell_only)\n",
    "    create_output_dirs(output_folder_bg_only)\n",
    "    \n",
    "    sequence_number = sequence_number -1\n",
    "\n",
    "# Apply the mask to each channel in each sequence (here an XY frame) and Z-plane, just use the current mask \n",
    "    if sequence_number < multi_page_tiff.shape[0]: \n",
    "    \n",
    "        for z in range(multi_page_tiff.shape[1]):\n",
    "            for channel in range(multi_page_tiff.shape[2]):\n",
    "                single_image = multi_page_tiff[sequence_number, z, channel, :, :]\n",
    "                single_image_cells = single_image * (masks > 0)\n",
    "                single_image_background = single_image * (masks == 0)\n",
    "                        \n",
    "                # Generate the output paths\n",
    "                output_cell_only_path = os.path.join(output_folder_cell_only, f\"frame_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                output_bg_only_path = os.path.join(output_folder_bg_only, f\"frame_{sequence_number}_Z_{z}_Channel_{channel}.tif\")\n",
    "                        \n",
    "                # Save the cell-only and background-only images\n",
    "                imwrite(output_cell_only_path, single_image_cells)\n",
    "                imwrite(output_bg_only_path, single_image_background)\n",
    "    else:\n",
    "            print(f\"Skipping {sequence_number} as it is out of bounds.\")\n",
    "\n",
    "    # Modify the output paths\n",
    "    output_cell_only_path = os.path.join(directory, 'cell_only', f\"{base_name}_cell_only.tif\")\n",
    "    output_background_only_path = os.path.join(directory, 'background_only', f\"{base_name}_background_only.tif\")\n",
    "    output_outlines_path = os.path.join(directory, 'outlines', f\"{base_name}_outlines.txt\")\n",
    "    output_mask_path = os.path.join(directory, 'masks', f\"{base_name}_mask.tif\")\n",
    "    \n",
    "    # Save the images and outlines\n",
    "    cellpose_io.outlines_to_text(output_outlines_path, label_image)\n",
    "    imwrite(output_mask_path, masks.astype(np.uint16))\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time for the code chunk: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Now that I have all of the images post mask processing in an organized format I can look into reading them into the memory and performing statistics on them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing Functions for Analysis and Metadata Assignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import ast \n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate image statistics\n",
    "def calculate_image_stats(image_path):\n",
    "    # Read the image\n",
    "    image = imread(image_path)\n",
    "    # Filter out the zero pixels\n",
    "    image = image[image > 0]\n",
    "    # Initialize a dictionary to store the statistics\n",
    "    stats_dict = {}\n",
    "    # Calculate statistics\n",
    "    stats_dict['mean'] = np.mean(image)\n",
    "    stats_dict['median'] = np.median(image)\n",
    "    stats_dict['max'] = np.max(image)\n",
    "    stats_dict['min'] = np.min(image)\n",
    "    stats_dict['std_dev'] = np.std(image)\n",
    "    stats_dict['skewness'] = scipy.stats.skew(image)\n",
    "    stats_dict['kurtosis'] = scipy.stats.kurtosis(image)\n",
    "    stats_dict['pixel_count'] = len(image)\n",
    "    stats_dict['area_covered'] = (len(image)/262144)\n",
    "    # Extract easy Metadata\n",
    "\n",
    "    # Extract metadata from the file path\n",
    "    p = Path(image_path)\n",
    "\n",
    "    ### From the deepest file level\n",
    "    try:\n",
    "        split_stem = p.stem.split('_')\n",
    "        frame = split_stem[1]\n",
    "        z_stack = split_stem[3]\n",
    "        channel = split_stem[5]\n",
    "        stats_dict['frame'] = frame\n",
    "        stats_dict['z_stack'] = z_stack\n",
    "        stats_dict['channel'] = channel\n",
    "        stats_dict['full_filepath'] = str(p)  # Adding full file path\n",
    "    except IndexError:\n",
    "        print(f\"Failed to extract frame, z_stack, channel from {p.stem}\")\n",
    "\n",
    "    ### From the directory structure\n",
    "    root_parts = root.split('\\\\')\n",
    "    try:\n",
    "        condition = root_parts[9].split('_')[-1].split('.')[0]  # 'inf' or 'uninf'\n",
    "        time = root_parts[9].split('_')[1]  # 10min, 20min, etc.\n",
    "        strain = root_parts[9].split('_')[2].split('.')[0]  # LZ222##\n",
    "        stats_dict['condition'] = condition\n",
    "        stats_dict['time'] = time\n",
    "        stats_dict['strain'] = strain\n",
    "    except IndexError:\n",
    "        print(f\"Failed to extract condition, time, strain from {root}\")\n",
    "\n",
    "    biorep = '1'  # All 1 in this case\n",
    "    stats_dict['biorep'] = biorep\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "# Function to extract metadata for channel naming\n",
    "def extract_metadata_channel(root_dir):\n",
    "    metadata_list = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.ome.tiff') or file.endswith('.ome.tif'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                reader = OmeTiffReader(full_path)\n",
    "                ome_metadata = reader.ome_metadata\n",
    "                channel_names = [channel.name for channel in ome_metadata.images[0].pixels.channels]\n",
    "                metadata_list.append({'full_filepath': full_path, 'channel_names': channel_names})\n",
    "    return pd.DataFrame(metadata_list)\n",
    "\n",
    "#import re  # Importing the regular expression library\n",
    "\n",
    "def merge_metadata(df, df_metadata, channel_map=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Merge metadata into the main dataframe based on matching 'full_filepath'.\n",
    "    A new column 'signal' is created based on the corresponding 'channel_names' from df_metadata.\n",
    "    Optionally, a channel_map can be provided to rename the channels.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The main dataframe containing various columns including 'full_filepath' and 'channel'.\n",
    "    df_metadata (DataFrame): Metadata dataframe containing 'full_filepath' and 'channel_names'.\n",
    "    channel_map (dict, optional): A dictionary to map original channel names to new names.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialize an empty list to hold the new 'signal' column values\n",
    "    signal_list = [None] * len(df)\n",
    "    \n",
    "    # Loop through each row in df\n",
    "    for i, row in df.iterrows():\n",
    "        # Loop through each row in df_metadata\n",
    "        for j, row_metadata in df_metadata.iterrows():\n",
    "            # Separate the root from the filename using rsplit\n",
    "            root_metadata = row_metadata['full_filepath'].rsplit('\\\\', 1)[0]\n",
    "            \n",
    "            # Create a regex pattern for the root\n",
    "            pattern = re.compile(re.escape(root_metadata))\n",
    "            \n",
    "            # Use regex to find if the root exists in 'full_filepath' of df\n",
    "            if pattern.search(row['full_filepath']):\n",
    "                # Check if the 'channel' value can be converted to an integer\n",
    "                try:\n",
    "                    channel_index = int(row['channel'])\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not convert channel value {row['channel']} to integer at row {i}.\")\n",
    "                    continue  # Skip this row and continue with the next one\n",
    "                \n",
    "                # Parse the string as a list\n",
    "                channel_names = ast.literal_eval(row_metadata['channel_names'])\n",
    "\n",
    "                if isinstance(row_metadata['channel_names'], str):\n",
    "                    try:\n",
    "                        channel_names = ast.literal_eval(row_metadata['channel_names'])\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Failed to parse channel_names at row {j} in df_metadata: {e}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    channel_names = row_metadata['channel_names']\n",
    "\n",
    "\n",
    "                # Check if channel_index is within the range of channel_names\n",
    "                if 0 <= channel_index < len(channel_names):\n",
    "                    signal_name = channel_names[channel_index]\n",
    "                    \n",
    "                    # Apply channel_map if provided\n",
    "                    if channel_map and signal_name in channel_map:\n",
    "                        signal_name = channel_map[signal_name]\n",
    "                    \n",
    "                    signal_list[i] = signal_name\n",
    "                else:\n",
    "                    print(f\"Warning: channel_index {channel_index} is out of range for channel_names {channel_names} at row {i}.\")\n",
    "                break  # No need to continue checking for this row, move on to the next one\n",
    "    \n",
    "    # Add the new 'signal' column to df\n",
    "    df['signal'] = signal_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics and Metadata Assignment Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: ['Phase', 'eGFP']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mh:\\Omni\\Image_Analysis\\Python\\omnipose_working_stats_matt_stats_calculated.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df_metadata \u001b[39m=\u001b[39m extract_metadata_channel(root_dir)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Merge the metadata into the DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m merge_metadata(df, df_metadata, channel_map \u001b[39m=\u001b[39;49m channel_map)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Show the DataFrame (For demonstration, will only display the head)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead())\n",
      "\u001b[1;32mh:\\Omni\\Image_Analysis\\Python\\omnipose_working_stats_matt_stats_calculated.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Skip this row and continue with the next one\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39m# Parse the string as a list\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m channel_names \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39;49mliteral_eval(row_metadata[\u001b[39m'\u001b[39;49m\u001b[39mchannel_names\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row_metadata[\u001b[39m'\u001b[39m\u001b[39mchannel_names\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X30sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mc:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32mc:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32mc:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Constant) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mvalue) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Nikon\\anaconda3\\envs\\omnipose\\lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m lno \u001b[39m:=\u001b[39m \u001b[39mgetattr\u001b[39m(node, \u001b[39m'\u001b[39m\u001b[39mlineno\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m on line \u001b[39m\u001b[39m{\u001b[39;00mlno\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: ['Phase', 'eGFP']"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store the image statistics and metadata\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Directory path (Replace this with the actual path)\n",
    "# root_dir = root_dir # this has been defined in the first chunk above, if need to redefine can do so here\n",
    "\n",
    "# Iterate through directories and sub-directories\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tif\") and ('cell_only' in root or 'background_only' in root):\n",
    "            file_path = os.path.join(root, file)\n",
    "            stats = calculate_image_stats(file_path)\n",
    "            df = pd.concat([df, pd.DataFrame([stats])], ignore_index=True)\n",
    "\n",
    "# Extract metadata for channel naming\n",
    "df_metadata = extract_metadata_channel(root_dir)\n",
    "\n",
    "# Merge the metadata into the DataFrame\n",
    "merge_metadata(df, df_metadata, channel_map = channel_map)\n",
    "\n",
    "# Show the DataFrame (For demonstration, will only display the head)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the filename\n",
    "filename = 'df.csv'\n",
    "\n",
    "# Create the full path by joining root_dir and filename\n",
    "full_path = os.path.join(root_dir, filename)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(full_path, index=False)\n",
    "\n",
    "\n",
    "df_metadata.to_csv(r'C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\df_metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, list)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_type_df = type(df.loc[0, 'channel'])\n",
    "channel_type_df_metadata = type(df_metadata.loc[0, 'channel_names'])\n",
    "\n",
    "channel_type_df, channel_type_df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              mean   median    max   min      std_dev  skewness  kurtosis  \\\n",
      "0    10242.878421  10060.0  19183  6387   870.647995  2.313901  8.834251   \n",
      "1     5763.509597   5732.0  15398  4049   470.939629  0.809239  4.273426   \n",
      "2    10212.855300  10028.0  19272  6139   872.961733  2.334621  8.966507   \n",
      "3     5452.585866   5430.0  13049  3663   435.475669  0.556898  2.232659   \n",
      "4    10192.152762  10013.0  18489  5804   858.448014  2.260109  8.405057   \n",
      "..            ...      ...    ...   ...          ...       ...       ...   \n",
      "245   9648.284247   9625.0  14566  7184   726.518150  0.280868  0.408741   \n",
      "246  23426.886832  23524.5  47023  7520  6191.949586  0.110423 -0.159910   \n",
      "247   7816.201070   7592.5  15360  4499  1533.609511  0.677385  0.164033   \n",
      "248   9379.229577   9356.0  13599  7132   674.217729  0.253921  0.319319   \n",
      "249  22991.614535  23118.0  45961  7287  5976.425770  0.112240 -0.159848   \n",
      "\n",
      "     pixel_count  area_covered  \\\n",
      "0         236793      0.903294   \n",
      "1         236793      0.903294   \n",
      "2         236793      0.903294   \n",
      "3         236793      0.903294   \n",
      "4         236793      0.903294   \n",
      "..           ...           ...   \n",
      "245        25608      0.097687   \n",
      "246        25608      0.097687   \n",
      "247        25608      0.097687   \n",
      "248        25608      0.097687   \n",
      "249        25608      0.097687   \n",
      "\n",
      "                                         full_filepath frame z_stack channel  \\\n",
      "0    C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     0       0       0   \n",
      "1    C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     0       0       1   \n",
      "2    C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     0       1       0   \n",
      "3    C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     0       1       1   \n",
      "4    C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     0       2       0   \n",
      "..                                                 ...   ...     ...     ...   \n",
      "245  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     2       3       1   \n",
      "246  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     2       3       2   \n",
      "247  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     2       4       0   \n",
      "248  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     2       4       1   \n",
      "249  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...     2       4       2   \n",
      "\n",
      "    condition     time strain biorep  \n",
      "0       uninf  LZ22225  10min      1  \n",
      "1       uninf  LZ22225  10min      1  \n",
      "2       uninf  LZ22225  10min      1  \n",
      "3       uninf  LZ22225  10min      1  \n",
      "4       uninf  LZ22225  10min      1  \n",
      "..        ...      ...    ...    ...  \n",
      "245       inf  LZ22225  20min      1  \n",
      "246       inf  LZ22225  20min      1  \n",
      "247       inf  LZ22225  20min      1  \n",
      "248       inf  LZ22225  20min      1  \n",
      "249       inf  LZ22225  20min      1  \n",
      "\n",
      "[250 rows x 17 columns]>\n",
      "                                       full_filepath        channel_names\n",
      "0  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...        [Phase, eGFP]\n",
      "1  C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\biorep...  [Phase, eGFP, DAPI]\n",
      "Index(['mean', 'median', 'max', 'min', 'std_dev', 'skewness', 'kurtosis',\n",
      "       'pixel_count', 'area_covered', 'full_filepath', 'frame', 'z_stack',\n",
      "       'channel', 'condition', 'time', 'strain', 'biorep'],\n",
      "      dtype='object')\n",
      "0\n",
      "<class 'str'>    250\n",
      "Name: full_filepath, dtype: int64\n",
      "C:\\Users\\Nikon\\Downloads\\Omni\\sandbox_2\\df.csv\n"
     ]
    }
   ],
   "source": [
    "# Mapping dictionary for renaming channels\n",
    "channel_map = {'Phase': 'phase', 'eGFP': 'fish', 'DAPI': 'dapi'}\n",
    "\n",
    "print(df.head)\n",
    "print(df_metadata)\n",
    "\n",
    "print(df.columns)\n",
    "print(df['full_filepath'].isna().sum())\n",
    "print(df['full_filepath'].apply(type).value_counts())\n",
    "print(full_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mh:\\Omni\\Image_Analysis\\Python\\omnipose_working_stats_matt_stats_calculated.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Omni/Image_Analysis/Python/omnipose_working_stats_matt_stats_calculated.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mint\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mchannel\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "print(int(row['channel']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnipose_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
